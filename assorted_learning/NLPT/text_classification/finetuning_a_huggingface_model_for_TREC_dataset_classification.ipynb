{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e1a6831",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0638177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "table.dataframe td, table.dataframe th {\n",
       "    border: 1px  black solid !important;\n",
       "  color: black !important;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style type=\"text/css\">\n",
    "table.dataframe td, table.dataframe th {\n",
    "    border: 1px  black solid !important;\n",
    "  color: black !important;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eedb6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, ClassLabel\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import torch\n",
    "from torch.nn.functional import cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eb3bebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "064bcf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/TREC_classes.pkl\", \"rb\") as file:\n",
    "    TREC_classes = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d840cc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = {\n",
    "    'train': 'TREC_question_classification/train/*.csv',\n",
    "    'test': 'TREC_question_classification/test/*.csv'\n",
    "}\n",
    "TREC = load_dataset('csv', data_files=data_files)\n",
    "class_labels = ClassLabel(names=TREC_classes)\n",
    "TREC = TREC.cast_column('label', class_labels)\n",
    "# this is a fifty class classification model\n",
    "num_classes = len(TREC['train'].features['label'].names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03df03db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_ckpt = 'distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt,\n",
    "                                                           num_labels=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eeb70e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch['question'], truncation=True, padding=True)\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {'accuracy': acc, 'f1': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32b75c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing the input, and setting it to tensor format\n",
    "TREC_encoded = TREC.map(tokenize, batched=True, batch_size=None)\n",
    "TREC_encoded.set_format('torch', columns=['label', 'input_ids', 'attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fedaf0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model on the training data.\n",
    "model_name = f'{model_ckpt}-finetuned-TREC-dataset'\n",
    "batch_size = 64\n",
    "logging_steps = len(TREC['train']) // batch_size\n",
    "train_args = TrainingArguments(output_dir=model_name,\n",
    "                               evaluation_strategy='epoch',\n",
    "                               per_device_train_batch_size=batch_size,\n",
    "                               per_device_eval_batch_size=batch_size,\n",
    "                               learning_rate=2e-5,\n",
    "                               weight_decay=0.01,\n",
    "                               num_train_epochs=5,\n",
    "                               log_level='error',\n",
    "                               disable_tqdm=False,\n",
    "                               push_to_hub=False,\n",
    "                               hub_token='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'\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a63fb276",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model, args=train_args,\n",
    "                  train_dataset=TREC_encoded['train'],\n",
    "                  eval_dataset=TREC_encoded['test'],\n",
    "                  compute_metrics=compute_metrics,\n",
    "                 tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73d738fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karvsmech/miniconda3/envs/ptorch/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1210' max='1210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1210/1210 03:00, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.208443</td>\n",
       "      <td>0.726000</td>\n",
       "      <td>0.660759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.798866</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.807543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.370300</td>\n",
       "      <td>0.643670</td>\n",
       "      <td>0.852000</td>\n",
       "      <td>0.828836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.370300</td>\n",
       "      <td>0.578458</td>\n",
       "      <td>0.874000</td>\n",
       "      <td>0.859577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.254000</td>\n",
       "      <td>0.567326</td>\n",
       "      <td>0.884000</td>\n",
       "      <td>0.872305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1210, training_loss=0.6970146242252067, metrics={'train_runtime': 180.2188, 'train_samples_per_second': 428.701, 'train_steps_per_second': 6.714, 'total_flos': 820255610547600.0, 'train_loss': 0.6970146242252067, 'epoch': 5.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84506b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.2369462 , -1.2023038 , -1.0174    , ..., -0.89801925,\n",
       "         0.7977742 , -0.75918317],\n",
       "       [-2.4245784 , -1.5209309 , -0.00859236, ..., -2.6680021 ,\n",
       "        -1.9946532 , -2.719173  ],\n",
       "       [-1.2595564 , -1.2557795 , -0.06258786, ..., -1.3581948 ,\n",
       "        -2.0361462 , -1.793386  ],\n",
       "       ...,\n",
       "       [-2.229744  , -0.80216616, -1.1742074 , ..., -2.1869643 ,\n",
       "        -1.3337531 , -2.1011848 ],\n",
       "       [-2.2594566 ,  0.95140016,  3.035543  , ..., -2.9332294 ,\n",
       "        -1.9684222 , -2.751257  ],\n",
       "       [-1.2841662 ,  2.50552   ,  7.7424617 , ..., -2.0258007 ,\n",
       "        -2.3634462 , -2.2467375 ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([40, 32, 28,  2, 39, 40, 29, 18,  5,  2, 32, 30, 49, 30, 39, 43, 22,\n",
       "       30,  2, 39, 30,  2, 35,  2,  2, 30,  2, 35, 35, 35, 46, 34,  2, 47,\n",
       "       39, 45, 35, 40, 38, 38, 18,  2,  2,  2,  6,  6, 45,  2, 38, 29,  2,\n",
       "       30, 30,  2,  3,  2, 39, 32, 32, 46, 32, 30, 35, 13, 36, 28, 25,  2,\n",
       "       39, 35, 43, 41, 32, 30, 35,  2, 10, 40, 49, 30,  2, 39, 30, 43, 39,\n",
       "        5,  2, 30,  2, 33, 12,  2, 47, 39, 29, 35, 39,  2,  2, 17,  2, 30,\n",
       "        4, 28, 32,  2, 47,  6, 39, 35,  8,  2, 40, 30, 18, 30, 39, 22, 39,\n",
       "       35, 39, 40,  2, 30, 40, 30, 40, 39,  2, 45, 40, 30,  2, 19,  2, 17,\n",
       "       35, 30, 31,  2,  2,  6, 35,  6,  2,  7, 30, 26,  2,  2, 25, 30,  2,\n",
       "       39, 29, 35, 32,  2, 35, 36,  2,  2, 39, 35, 25, 35, 39,  2, 36, 30,\n",
       "       39, 46, 39,  2, 35, 36, 35, 39,  8, 40, 35,  2, 35,  2, 22, 30, 30,\n",
       "        2, 35, 22, 17, 40, 45, 39,  2, 32, 10, 30, 19, 22, 19, 32, 30,  6,\n",
       "       43, 35, 30, 47,  3,  3, 39, 46, 36, 35,  2, 15,  2, 25, 38,  2,  2,\n",
       "       39,  2, 17, 34, 22, 43,  3, 35, 30, 39, 30,  2, 38, 17,  2, 35,  2,\n",
       "       35, 46, 36,  2,  5,  2,  2, 35,  2,  2,  3, 17, 30, 32, 17, 22,  2,\n",
       "       35, 40, 25,  2, 41, 30, 30, 38, 14, 45,  2,  2, 32, 45,  4, 15,  3,\n",
       "        2, 30,  2,  5,  2, 39,  0, 22, 35, 30,  1,  2, 35,  2,  2,  2,  2,\n",
       "        2, 32, 11, 43, 25,  2,  2,  8, 45, 17,  8,  1, 39,  2, 39, 39, 35,\n",
       "       30, 35, 30, 39, 32, 35, 38,  2, 35,  2, 30, 35, 17, 35,  2, 39,  1,\n",
       "        8, 39,  1,  5, 41, 39,  2,  2, 39,  6, 26, 43, 35,  2, 13,  2, 44,\n",
       "       49, 12, 44, 30, 43, 30, 11,  3, 39,  2, 39, 35, 18,  6,  2, 30, 46,\n",
       "       40,  5,  6,  2,  2,  7, 43,  2, 40,  8,  8,  2, 35, 49, 10,  2,  2,\n",
       "       13, 39, 35,  2,  1,  2, 30, 30, 22, 30, 45, 39,  2, 30,  2,  2, 30,\n",
       "        2,  6, 43,  2,  2,  2, 43, 44, 34, 30, 22, 39,  1, 40, 32,  2, 35,\n",
       "       39,  2, 30, 22, 32,  1, 18,  2,  2,  2, 30, 30, 39, 35, 26,  2, 35,\n",
       "       17,  2, 35,  2, 30,  2,  6, 35, 30,  2,  2,  2, 39,  1,  6, 30, 22,\n",
       "       33,  6, 30,  6, 35, 30, 39,  6,  8, 21, 13, 39, 47, 39,  8, 35,  2,\n",
       "        2, 29,  6, 35, 39, 36, 25,  2, 29,  2,  2,  2,  2, 10, 43, 17, 10,\n",
       "        2, 32,  8, 33, 19, 22, 22,  2, 35,  2, 32, 40, 17, 26,  2,  2, 24,\n",
       "       39, 38, 30, 10, 38, 22,  2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.5673259496688843,\n",
       " 'test_accuracy': 0.884,\n",
       " 'test_f1': 0.8723049773203582,\n",
       " 'test_runtime': 0.2331,\n",
       " 'test_samples_per_second': 2145.38,\n",
       " 'test_steps_per_second': 34.326}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_output = trainer.predict(TREC_encoded['test'])\n",
    "prediction_output.predictions\n",
    "prediction_output.label_ids\n",
    "prediction_output.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c058dba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(prediction_output.label_ids, \n",
    "#                  prediction_output.predictions.argmax(-1),\n",
    "#                  normalize='true')\n",
    "# fig, ax = plt.subplots(figsize=(12, 15))\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "# disp.plot(cmap='Blues', ax=ax, values_format='.2f', colorbar=False)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4128640b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# error analysis\n",
    "def forward_pass_with_label(batch):\n",
    "    inputs = {k:v.to(device) for k, v in batch.items() if k in tokenizer.model_input_names}\n",
    "    outputs = model(**inputs)\n",
    "    pred_labels = outputs.logits.argmax(-1)\n",
    "    loss = cross_entropy(outputs.logits, batch['label'].to(device), reduction='none')\n",
    "    return {'predicted_labels':pred_labels, \n",
    "           'loss':loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2deead75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2e9d5767ae4882a105bd213abc6bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TREC_encoded['test'] = TREC_encoded['test'].map(forward_pass_with_label, batched=True, batch_size=None)\n",
    "TREC_encoded.set_format('pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0ecf5064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integer2string(row):\n",
    "    return TREC_encoded['train'].features['label'].int2str(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "172a6a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['question', 'label', 'predicted_labels', 'loss']\n",
    "df_error = TREC_encoded['test'][:][cols]\n",
    "df_error['label'] = df_error['label'].apply(lambda x: integer2string(x))\n",
    "df_error['predicted_labels'] = df_error['predicted_labels'].apply(lambda x: integer2string(x))\n",
    "df_error.sort_values(by=['loss'], inplace=True, ascending=False)\n",
    "df_error.to_csv('../data/TREC_error_analysis.csv', index=False, index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d21e93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b56e00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55d796f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279d1252",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptorch",
   "language": "python",
   "name": "ptorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
